{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e42540d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on PyMC v4.2.2\n"
     ]
    }
   ],
   "source": [
    "from utilities import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "import pymc as pm\n",
    "import aesara.tensor as at\n",
    "from create_training_instance_dictionary_with_covariates import *\n",
    "from feature_extraction import *\n",
    "from sample_from_full_model import *\n",
    "# Initialize random number generator\n",
    "RANDOM_SEED = 42\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "print(f\"Running on PyMC v{pm.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "467673da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done finding 154 training instances with at least 4 M protein measurements.\n",
      "Adding clinical covariates and treatment as covariate\n",
      "Number of clinical covariates including drug indicators: 13\n",
      "Adding clinical covariates by EHR\n",
      "How many from EHR not in current COMMPASS name list (due to inclusion criteria not being satisfied)\n",
      ": 664\n",
      "How many from current COMMPASS not in EHR name list: 0\n",
      "How many overlapping: 96\n",
      "Removing the homebrewed ones...\n",
      "Any nan values in df_EHR? True\n",
      "Any nan values in df_clinical_covariates? False\n",
      "Any nan values in df_X_covariates? True\n",
      "Which are nan values in df_EHR?\n",
      "     censpfs  pfscdy  censos  oscdy  D_PT_age  D_PT_iss  Triplet   ecog   IMID  \\\n",
      "0     False   False   False  False     False     False    False  False  False   \n",
      "1     False   False   False  False     False     False    False  False  False   \n",
      "2     False   False   False  False     False     False    False  False  False   \n",
      "3     False   False   False  False     False     False    False  False  False   \n",
      "4     False   False   False  False     False     False    False  False  False   \n",
      "..      ...     ...     ...    ...       ...       ...      ...    ...    ...   \n",
      "91    False   False   False  False     False     False    False  False  False   \n",
      "92    False   False   False  False     False      True    False  False  False   \n",
      "93    False   False   False  False     False     False    False  False  False   \n",
      "94    False   False   False  False     False     False    False  False  False   \n",
      "95    False   False   False  False     False     False    False  False  False   \n",
      "\n",
      "      KAR  ...  APOBEC   BRAF   DIS3  FAM46C   NRAS   KRAS   TP53  TRAF3  \\\n",
      "0   False  ...   False  False  False   False  False  False  False  False   \n",
      "1   False  ...   False  False  False   False  False  False  False  False   \n",
      "2   False  ...   False  False  False   False  False  False  False  False   \n",
      "3   False  ...   False  False  False   False  False  False  False  False   \n",
      "4   False  ...   False  False  False   False  False  False  False  False   \n",
      "..    ...  ...     ...    ...    ...     ...    ...    ...    ...    ...   \n",
      "91  False  ...   False  False  False   False  False  False  False  False   \n",
      "92  False  ...   False  False  False   False  False  False  False  False   \n",
      "93  False  ...   False  False  False   False  False  False  False  False   \n",
      "94  False  ...   False  False  False   False  False  False  False  False   \n",
      "95  False  ...   False  False  False   False  False  False  False  False   \n",
      "\n",
      "    TP53_factor  MAF_MAFB  \n",
      "0         False     False  \n",
      "1         False     False  \n",
      "2         False     False  \n",
      "3         False     False  \n",
      "4         False     False  \n",
      "..          ...       ...  \n",
      "91        False     False  \n",
      "92        False     False  \n",
      "93        False     False  \n",
      "94        False     False  \n",
      "95        False     False  \n",
      "\n",
      "[96 rows x 53 columns]\n",
      "These columns have nan values: ['D_PT_iss', 'ecog', 'ISS', 'APOBEC', 'BRAF', 'DIS3', 'FAM46C', 'NRAS', 'KRAS', 'TP53', 'TRAF3', 'TP53_factor']\n",
      "D_PT_iss has 1 nan values.\n",
      "ecog has 2 nan values.\n",
      "ISS has 1 nan values.\n",
      "APOBEC has 1 nan values.\n",
      "BRAF has 1 nan values.\n",
      "DIS3 has 1 nan values.\n",
      "FAM46C has 1 nan values.\n",
      "NRAS has 1 nan values.\n",
      "KRAS has 1 nan values.\n",
      "TP53 has 1 nan values.\n",
      "TRAF3 has 1 nan values.\n",
      "TP53_factor has 1 nan values.\n",
      "Missing data filled with naive means not per group\n",
      "These columns have nan values: []\n",
      "Before standardizing:\n",
      "   censpfs    pfscdy  censos     oscdy  D_PT_age  D_PT_iss  Triplet      ecog  \\\n",
      "0        1  0.597260       0  6.304110        64       1.0        0  0.000000   \n",
      "1        1  0.698630       1  2.273973        47       2.0        1  1.000000   \n",
      "2        1  3.052055       0  5.893151        60       3.0        0  0.000000   \n",
      "3        1  1.709589       1  3.205479        54       3.0        0  0.000000   \n",
      "4        1  3.923288       0  5.336986        64       1.0        1  1.000000   \n",
      "5        1  1.169863       1  1.575342        82       2.0        1  2.000000   \n",
      "6        1  0.123288       1  0.123288        68       3.0        0  0.000000   \n",
      "7        1  1.221918       0  4.624658        93       1.0        1  0.000000   \n",
      "8        0  0.917808       0  1.745205        61       3.0        1  0.734043   \n",
      "9        1  0.956164       1  2.753425        72       1.0        1  1.000000   \n",
      "\n",
      "   IMID  KAR  ...  APOBEC  BRAF  DIS3  FAM46C  NRAS  KRAS  TP53  TRAF3  \\\n",
      "0     1    0  ...     0.0   0.0   0.0     0.0   0.0   0.0   0.0    0.0   \n",
      "1     1    0  ...     0.0   0.0   0.0     1.0   0.0   1.0   0.0    0.0   \n",
      "2     0    0  ...     0.0   0.0   0.0     0.0   0.0   0.0   0.0    0.0   \n",
      "3     0    0  ...     0.0   0.0   0.0     0.0   0.0   1.0   0.0    0.0   \n",
      "4     1    0  ...     0.0   0.0   0.0     0.0   1.0   0.0   0.0    0.0   \n",
      "5     1    0  ...     0.0   0.0   0.0     0.0   1.0   0.0   0.0    0.0   \n",
      "6     1    0  ...     0.0   0.0   0.0     0.0   0.0   0.0   0.0    0.0   \n",
      "7     1    0  ...     1.0   0.0   0.0     0.0   0.0   0.0   1.0    0.0   \n",
      "8     1    0  ...     0.0   0.0   0.0     0.0   0.0   0.0   0.0    0.0   \n",
      "9     1    0  ...     0.0   0.0   0.0     0.0   1.0   0.0   0.0    0.0   \n",
      "\n",
      "   TP53_factor  MAF_MAFB  \n",
      "0          0.0         0  \n",
      "1          0.0         0  \n",
      "2          0.0         0  \n",
      "3          0.0         0  \n",
      "4          0.0         0  \n",
      "5          0.0         0  \n",
      "6          0.0         0  \n",
      "7          2.0         0  \n",
      "8          0.0         0  \n",
      "9          0.0         0  \n",
      "\n",
      "[10 rows x 53 columns]\n",
      "Standardizing some...\n",
      "Total number of covariates in df_X: 53\n",
      "   censpfs    pfscdy  censos     oscdy  D_PT_age  D_PT_iss  Triplet      ecog  \\\n",
      "0        1 -1.212750       0  1.806804 -0.036668       1.0        0  0.000000   \n",
      "1        1 -1.146330       1 -0.742525 -1.571072       2.0        1  1.000000   \n",
      "2        1  0.395673       0  1.546845 -0.397704       3.0        0  0.000000   \n",
      "3        1 -0.483933       1 -0.153285 -0.939259       3.0        0  0.000000   \n",
      "4        1  0.966520       0  1.195034 -0.036668       1.0        1  1.000000   \n",
      "5        1 -0.837571       1 -1.184455  1.587996       2.0        1  2.000000   \n",
      "6        1 -1.523304       1 -2.102976  0.324369       3.0        0  0.000000   \n",
      "7        1 -0.803463       0  0.744439  2.580846       1.0        1  0.000000   \n",
      "8        0 -1.002721       0 -1.077006 -0.307445       3.0        1  0.734043   \n",
      "9        1 -0.977590       1 -0.439240  0.685405       1.0        1  1.000000   \n",
      "\n",
      "   IMID  KAR  ...  APOBEC  BRAF  DIS3  FAM46C  NRAS  KRAS  TP53  TRAF3  \\\n",
      "0     1    0  ...     0.0   0.0   0.0     0.0   0.0   0.0   0.0    0.0   \n",
      "1     1    0  ...     0.0   0.0   0.0     1.0   0.0   1.0   0.0    0.0   \n",
      "2     0    0  ...     0.0   0.0   0.0     0.0   0.0   0.0   0.0    0.0   \n",
      "3     0    0  ...     0.0   0.0   0.0     0.0   0.0   1.0   0.0    0.0   \n",
      "4     1    0  ...     0.0   0.0   0.0     0.0   1.0   0.0   0.0    0.0   \n",
      "5     1    0  ...     0.0   0.0   0.0     0.0   1.0   0.0   0.0    0.0   \n",
      "6     1    0  ...     0.0   0.0   0.0     0.0   0.0   0.0   0.0    0.0   \n",
      "7     1    0  ...     1.0   0.0   0.0     0.0   0.0   0.0   1.0    0.0   \n",
      "8     1    0  ...     0.0   0.0   0.0     0.0   0.0   0.0   0.0    0.0   \n",
      "9     1    0  ...     0.0   0.0   0.0     0.0   1.0   0.0   0.0    0.0   \n",
      "\n",
      "   TP53_factor  MAF_MAFB  \n",
      "0          0.0         0  \n",
      "1          0.0         0  \n",
      "2          0.0         0  \n",
      "3          0.0         0  \n",
      "4          0.0         0  \n",
      "5          0.0         0  \n",
      "6          0.0         0  \n",
      "7          2.0         0  \n",
      "8          0.0         0  \n",
      "9          0.0         0  \n",
      "\n",
      "[10 rows x 53 columns]\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "# Load data\n",
    "# Load dummy_patient_dict\n",
    "#patient_dictionary = np.load(\"./binaries_and_pickles/dummy_patient_dict.npy\", allow_pickle=True).item()\n",
    "M_number_of_measurements = 4\n",
    "patient_dictionary, training_instance_dict = create_training_instance_dictionary_with_covariates(minimum_number_of_measurements=M_number_of_measurements, global_treatment_id_list = [1,2,3,7,10,13,15,16], verbose=False)\n",
    "# Dimensions: \n",
    "# y: M_max * N\n",
    "# t: M_max * N\n",
    "# X: P * N\n",
    "# Subset data\n",
    "# Create a training_instance dictionary with covariates and M proteins only in the period of interest. \n",
    "#   Idea 1: The drug during the treatment is the only X. Shows you the drug's effect on the mean growth rates. \n",
    "#   Idea 2: For each drug, find which factors determine the response. \n",
    "\n",
    "#for name, patient in patient_dictionary.items():\n",
    "#    plot_true_mprotein_with_observations_and_treatments_and_estimate(Parameters(0.1, 0.1, 0.001, -0.001, 0, 0.1), patient, estimated_parameters=[], PLOT_ESTIMATES=False, plot_title=str(name), savename=\"./plots/Bayes_simulated_data/COMMPASS/\"+str(name))\n",
    "\n",
    "# This could be a function dict, Y, t = standardize_input_from_dictionary: \n",
    "N_patients = len(patient_dictionary)\n",
    "y_pre_padding = np.array([patient.Mprotein_values for _, patient in patient_dictionary.items()])\n",
    "#y_pre_padding = max(y_pre_padding,0)\n",
    "times_pre_padding = np.array([patient.measurement_times for _, patient in patient_dictionary.items()])\n",
    "times_pre_padding = [t_list-t_list[0] for t_list in times_pre_padding]# Account for nonzero time 0\n",
    "len_y_each_patient = np.array([len(elem) for elem in times_pre_padding])\n",
    "max_len_y = max(len_y_each_patient)\n",
    "y = np.array([[np.nan for tt in range(max_len_y)] for ii in range(N_patients)])\n",
    "times = np.array([[np.nan for tt in range(max_len_y)] for ii in range(N_patients)])\n",
    "for i in range(N_patients):\n",
    "    for t in range(len_y_each_patient[i]):\n",
    "        y[i][t] = y_pre_padding[i][t]\n",
    "        times[i][t] = times_pre_padding[i][t]\n",
    "\n",
    "# Use only fully observed part of data to get fully observed y and t: \n",
    "# Scale up Y to get it on a scale further away from zero\n",
    "y = 100*np.array([elem[0:M_number_of_measurements] for elem in y])\n",
    "times = np.array([elem[0:M_number_of_measurements] for elem in times])\n",
    "\n",
    "# y and times are cropped: Update the patient dictionary \n",
    "dummy_patient_dict  = {}\n",
    "for training_instance_id in range(0, N_patients):\n",
    "    dummy_patient_dict[training_instance_id] = patient_dictionary[training_instance_id]\n",
    "    dummy_patient_dict[training_instance_id].measurement_times = times[training_instance_id]\n",
    "    dummy_patient_dict[training_instance_id].Mprotein_values = y[training_instance_id]\n",
    "patient_dictionary = dummy_patient_dict\n",
    "\n",
    "# Keep only patients that are in EHR data: \n",
    "COMMPASS_current_name_list = [elem[0] for elem in training_instance_dict.values()]\n",
    "df_EHR = pd.read_excel('./COMMPASS_data/220615_commpass_clinical_genomic_annotated_EHR.xlsx')\n",
    "EHR_name_list = [elem.replace(\"_1_BM\" ,\"\", 1) for elem in df_EHR.loc[:,\"sample\"]]\n",
    "NEW_TRAIN_ID = 0\n",
    "new_patient_dictionary = {}\n",
    "new_training_instance_dict = {}\n",
    "for training_instance_id, patient in patient_dictionary.items(): # Dummy dictionary has training_instance_id as key\n",
    "    this_name = COMMPASS_current_name_list[training_instance_id]\n",
    "    if this_name in EHR_name_list: \n",
    "        new_patient_dictionary[NEW_TRAIN_ID] = patient_dictionary[training_instance_id] # equal to: \"= patient\"\n",
    "        new_training_instance_dict[NEW_TRAIN_ID] = training_instance_dict[training_instance_id]\n",
    "        NEW_TRAIN_ID = NEW_TRAIN_ID + 1\n",
    "N_patients = NEW_TRAIN_ID + 1\n",
    "# This resets from \"patient_dictionary, training_instance_dict = create_training_instance_dictionary_with_covariates\"\n",
    "patient_dictionary = new_patient_dictionary\n",
    "training_instance_dict = new_training_instance_dict\n",
    "\n",
    "X = feature_extraction(training_instance_dict)\n",
    "_, P = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7455821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunningCOMMPASS_M_4_P_53_N_patients_97_psi_prior_normal_N_samples_3000_N_tuning_3000_target_accept_0.99_max_treedepth_10_FUNNEL_REPARAMETRIZATION_True\n",
      "Max(Y): 910.0\n",
      "Max(t): 987.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: [Y_obs, alpha, c2_pi_r, c2_rho_r, c2_rho_s, lam_pi_r, lam_rho_r, lam_rho_s, omega, psi, sigma_obs, tau_pi_r, tau_rho_r, tau_rho_s, theta_pi_r_offset, theta_rho_r_offset, theta_rho_s_offset, z_pi_r, z_rho_r, z_rho_s]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [sigma_obs, alpha, tau_rho_s, tau_rho_r, tau_pi_r, lam_rho_s, lam_rho_r, lam_pi_r, c2_rho_s, c2_rho_r, c2_pi_r, z_rho_s, z_rho_r, z_pi_r, omega, theta_rho_s_offset, theta_rho_r_offset, theta_pi_r_offset, psi]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='10870' class='' max='24000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      45.29% [10870/24000 48:36&lt;58:42 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "psi_prior=\"normal\"\n",
    "N_samples = 3000\n",
    "N_tuning = 3000\n",
    "target_accept = 0.99\n",
    "max_treedepth = 10\n",
    "FUNNEL_REPARAMETRIZATION = True\n",
    "name = \"COMMPASS_M_\"+str(M_number_of_measurements)+\"_P_\"+str(P)+\"_N_patients_\"+str(N_patients)+\"_psi_prior_\"+psi_prior+\"_N_samples_\"+str(N_samples)+\"_N_tuning_\"+str(N_tuning)+\"_target_accept_\"+str(target_accept)+\"_max_treedepth_\"+str(max_treedepth)+\"_FUNNEL_REPARAMETRIZATION_\"+str(FUNNEL_REPARAMETRIZATION)\n",
    "print(\"Running\"+name)\n",
    "idata = sample_from_full_model(X, patient_dictionary, name, N_samples=N_samples, N_tuning=N_tuning, target_accept=target_accept, max_treedepth=max_treedepth, psi_prior=psi_prior, FUNNEL_REPARAMETRIZATION=FUNNEL_REPARAMETRIZATION)\n",
    "# This is an xArray: https://docs.xarray.dev/en/v2022.11.0/user-guide/data-structures.html\n",
    "print(\"Done sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88000c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convergence checks\n",
    "def quasi_geweke_test(idata, first=0.1, last=0.5, intervals=20):\n",
    "    print(\"Running Geweke test...\")\n",
    "    convergence_flag = True\n",
    "    for var_name in ['alpha', 'beta_rho_s', 'beta_rho_r', 'beta_pi_r', 'omega', 'theta_rho_s', 'theta_rho_r', 'theta_pi_r', 'rho_s', 'rho_r', 'pi_r']:\n",
    "        sample_shape = idata.posterior[var_name].shape\n",
    "        n_chains = sample_shape[0]\n",
    "        n_samples = sample_shape[1]\n",
    "        var_dims = sample_shape[2]\n",
    "        for chain in range(n_chains):\n",
    "            for dim in range(var_dims):\n",
    "                all_samples = np.ravel(idata.posterior[var_name][chain,:,dim])\n",
    "                first_part = all_samples[0:int(n_samples*first)]\n",
    "                last_part = all_samples[n_samples-int(n_samples*last):n_samples]\n",
    "                z_score = (np.mean(first_part)-np.mean(last_part)) / np.sqrt(np.var(first_part)+np.var(last_part))\n",
    "                if abs(z_score) >= 1.960:\n",
    "                    convergence_flag = False\n",
    "                    print(\"Seems like chain\",chain,\"has not converged in\",var_name,\"dimension\",dim,\": z_score is\",z_score)\n",
    "    for var_name in ['sigma_obs']:\n",
    "        all_samples = np.ravel(idata.posterior[var_name])\n",
    "        n_samples = len(all_samples)\n",
    "        first_part = all_samples[0:int(n_samples*first)]\n",
    "        last_part = all_samples[n_samples-int(n_samples*last):n_samples]\n",
    "        z_score = (np.mean(first_part)-np.mean(last_part)) / np.sqrt(np.var(first_part)+np.var(last_part))\n",
    "        if abs(z_score) >= 1.960:\n",
    "            convergence_flag = False\n",
    "            print(\"Seems like chain\",chain,\"has not converged in\",var_name,\"dimension\",dim,\": z_score is\",z_score)\n",
    "    if convergence_flag:\n",
    "        print(\"All chains seem to have converged.\")\n",
    "    return 0\n",
    "\n",
    "quasi_geweke_test(idata, first=0.1, last=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb667b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autocorrelation plots: \n",
    "az.plot_autocorr(idata, var_names=[\"sigma_obs\"]);\n",
    "az.plot_autocorr(idata, var_names=[\"alpha\"]);\n",
    "az.plot_autocorr(idata, var_names=[\"beta_rho_s\"]);\n",
    "az.plot_autocorr(idata, var_names=[\"beta_rho_r\"]);\n",
    "az.plot_autocorr(idata, var_names=[\"beta_pi_r\"]);\n",
    "az.plot_autocorr(idata, var_names=[\"omega\"]);\n",
    "az.plot_autocorr(idata, var_names=[\"sigma_obs\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91687f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior means \n",
    "print(\"List of covariates:\", idata.posterior.coords['predictors'])\n",
    "print('Posterior average of alpha:\\n', np.mean(idata.posterior['alpha'], axis=(0,1)))\n",
    "print('\\nPosterior average of beta_rho_s:\\n', np.mean(idata.posterior['beta_rho_s'], axis=(0,1)))\n",
    "print('\\nPosterior average of beta_rho_r:\\n', np.mean(idata.posterior['beta_rho_r'], axis=(0,1)))\n",
    "print('\\nPosterior average of beta_pi_r:\\n', np.mean(idata.posterior['beta_pi_r'], axis=(0,1)))\n",
    "print('\\nPosterior average of omega:\\n', np.mean(idata.posterior['omega'], axis=(0,1)))\n",
    "print('\\nPosterior average of sigma_obs:\\n', np.mean(idata.posterior['sigma_obs'], axis=(0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fb9f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(idata, var_names=('alpha', 'beta_rho_s', 'beta_rho_r', 'beta_pi_r', 'omega', 'sigma_obs'), combined=True)\n",
    "plt.savefig(\"./plots/posterior_plots/\"+name+\"-plot_posterior_group_parameters.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4411f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined means combine the chains into one posterior. Compact means split into different subplots\n",
    "az.plot_trace(idata, var_names=('beta_rho_s'), lines=[('beta_rho_s', {}, [0])], combined=False, compact=False)\n",
    "# There seems to be an effect where Age contributes towards higher growth rate for sensitive cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81203d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined means combine the chains into one posterior. Compact means split into different subplots\n",
    "az.plot_trace(idata, var_names=('beta_rho_r'), lines=[('beta_rho_r', {}, [0])], combined=False, compact=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77066926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined means combine the chains into one posterior. Compact means split into different subplots\n",
    "az.plot_trace(idata, var_names=('beta_pi_r'), lines=[('beta_pi_r', {}, [0])], combined=False, compact=False)\n",
    "# There is also an effect where there are less resistant cells for the older patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bbfd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if psi_prior==\"lognormal\":\n",
    "    az.plot_trace(idata, var_names=('xi'), combined=True)\n",
    "    plt.savefig(\"./plots/posterior_plots/\"+name+\"-plot_posterior_group_parameters_xi.png\")\n",
    "    plt.close()\n",
    "az.plot_trace(idata, var_names=('theta_rho_s', 'theta_rho_r', 'theta_pi_r', 'rho_s', 'rho_r', 'pi_r'), combined=True)\n",
    "plt.savefig(\"./plots/posterior_plots/\"+name+\"-plot_posterior_individual_parameters.png\")\n",
    "plt.close()\n",
    "# Test of exploration \n",
    "az.plot_energy(idata)\n",
    "plt.savefig(\"./plots/posterior_plots/\"+name+\"-plot_energy.png\")\n",
    "plt.close()\n",
    "# Plot of coefficients\n",
    "az.plot_forest(idata, var_names=[\"alpha\"], combined=True, hdi_prob=0.95, r_hat=True)\n",
    "plt.savefig(\"./plots/posterior_plots/\"+name+\"-plot_forest_alpha.png\")\n",
    "az.plot_forest(idata, var_names=[\"beta_rho_s\"], combined=True, hdi_prob=0.95, r_hat=True, rope=(0,0))\n",
    "plt.savefig(\"./plots/posterior_plots/\"+name+\"-plot_forest_beta_rho_s.png\")\n",
    "plt.close()\n",
    "az.plot_forest(idata, var_names=[\"beta_rho_r\"], combined=True, hdi_prob=0.95, r_hat=True, rope=(0,0))\n",
    "plt.savefig(\"./plots/posterior_plots/\"+name+\"-plot_forest_beta_rho_r.png\")\n",
    "plt.close()\n",
    "az.plot_forest(idata, var_names=[\"beta_pi_r\"], combined=True, hdi_prob=0.95, r_hat=True, rope=(0,0))\n",
    "plt.savefig(\"./plots/posterior_plots/\"+name+\"-plot_forest_beta_pi_r.png\")\n",
    "plt.close()\n",
    "az.plot_forest(idata, var_names=[\"theta_rho_s\"], combined=True, hdi_prob=0.95, r_hat=True)\n",
    "plt.savefig(\"./plots/posterior_plots/\"+name+\"-plot_forest_theta_rho_s.png\")\n",
    "plt.close()\n",
    "az.plot_forest(idata, var_names=[\"theta_rho_r\"], combined=True, hdi_prob=0.95, r_hat=True)\n",
    "plt.savefig(\"./plots/posterior_plots/\"+name+\"-plot_forest_theta_rho_r.png\")\n",
    "plt.close()\n",
    "az.plot_forest(idata, var_names=[\"theta_pi_r\"], combined=True, hdi_prob=0.95, r_hat=True)\n",
    "plt.savefig(\"./plots/posterior_plots/\"+name+\"-plot_forest_theta_pi_r.png\")\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
