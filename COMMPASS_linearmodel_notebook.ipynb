{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e653bba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "import pymc as pm\n",
    "import aesara.tensor as at\n",
    "from create_training_instance_dictionary_with_covariates import *\n",
    "from feature_extraction import *\n",
    "from sample_from_full_model import *\n",
    "# Initialize random number generator\n",
    "RANDOM_SEED = 42\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "print(f\"Running on PyMC v{pm.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f10b0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training_instance_dict and extract features\n",
    "##############################\n",
    "# Load data and create a training_instance dictionary with covariates and M proteins only in the period of interest. \n",
    "DATA_CHOICE = \"FISH_only\"\n",
    "M_number_of_measurements = 6\n",
    "treat_id = 16\n",
    "list_of_included_treatments = [treat_id] #[1,2,3,7,10,13,15,16]\n",
    "patient_dictionary, training_instance_dict = create_training_instance_dictionary_with_covariates(minimum_number_of_measurements=M_number_of_measurements, global_treatment_id_list=list_of_included_treatments, verbose=False)\n",
    "# Keep only patients that are in EHR data: \n",
    "COMMPASS_current_name_list = [elem[0] for elem in training_instance_dict.values()]\n",
    "df_EHR = pd.read_excel('./COMMPASS_data/220615_commpass_clinical_genomic_annotated_EHR.xlsx')\n",
    "EHR_name_list = [elem.replace(\"_1_BM\" ,\"\", 1) for elem in df_EHR.loc[:,\"sample\"]]\n",
    "NEW_TRAIN_ID = 0\n",
    "new_patient_dictionary = {}\n",
    "new_training_instance_dict = {}\n",
    "for training_instance_id, patient in patient_dictionary.items(): # Dummy dictionary has training_instance_id as key\n",
    "    this_name = COMMPASS_current_name_list[training_instance_id]\n",
    "    if this_name in EHR_name_list: \n",
    "        new_patient_dictionary[NEW_TRAIN_ID] = patient_dictionary[training_instance_id] # equal to: \"= patient\"\n",
    "        new_training_instance_dict[NEW_TRAIN_ID] = training_instance_dict[training_instance_id]\n",
    "        NEW_TRAIN_ID = NEW_TRAIN_ID + 1\n",
    "patient_dictionary = new_patient_dictionary\n",
    "training_instance_dict = new_training_instance_dict\n",
    "\n",
    "#for name, patient in patient_dictionary.items():\n",
    "#    plot_true_mprotein_with_observations_and_treatments_and_estimate(Parameters(0.1, 0.1, 0.001, -0.001, 0, 0.1), patient, estimated_parameters=[], PLOT_ESTIMATES=False, plot_title=str(name), savename=\"./plots/Bayes_simulated_data/COMMPASS/\"+str(name))\n",
    "\n",
    "# Here we also reset so the time of first M protein measurement is at time zero! History is also made relative to that time. \n",
    "# And we also crop the history so that it stops at the last M protein measurement, since we are cropping the M protein lists. \n",
    "def standardize_Y_arrays(patient_dictionary):\n",
    "    # standardize_input_from_dictionary\n",
    "    y_pre_padding = np.array([patient.Mprotein_values for _, patient in patient_dictionary.items()]) #y_pre_padding = max(y_pre_padding,0)\n",
    "    times_pre_padding = np.array([patient.measurement_times for _, patient in patient_dictionary.items()])\n",
    "    # Reset time of \"history\" to match (history here is the acutal observed period)\n",
    "    for ii, patient in patient_dictionary.items():\n",
    "        patient.treatment_history = [Treatment(treat_i.start-times_pre_padding[ii][0], treat_i.end-times_pre_padding[ii][0], treat_i.id) for treat_i in patient.treatment_history]\n",
    "        # This is incorrect/simplified for plotting: patient.treatment_history = [Treatment(patient.measurement_times[0], patient.measurement_times[-1], 0)]\n",
    "    times_pre_padding = [t_list-t_list[0] for t_list in times_pre_padding]# Account for nonzero time 0\n",
    "    len_y_each_patient = np.array([len(elem) for elem in times_pre_padding])\n",
    "    max_len_y = max(len_y_each_patient)\n",
    "    y = np.array([[np.nan for tt in range(max_len_y)] for ii in range(len(patient_dictionary))])\n",
    "    times = np.array([[np.nan for tt in range(max_len_y)] for ii in range(len(patient_dictionary))])\n",
    "    for i in range(len(patient_dictionary)):\n",
    "        for t in range(len_y_each_patient[i]):\n",
    "            y[i][t] = y_pre_padding[i][t]\n",
    "            times[i][t] = times_pre_padding[i][t]\n",
    "\n",
    "    # Scale up Y to get it on a scale further away from zero\n",
    "    y = 100*np.array([elem[0:M_number_of_measurements] for elem in y])\n",
    "    times = np.array([elem[0:M_number_of_measurements] for elem in times])\n",
    "\n",
    "    # y and times are cropped: Update the patient dictionary \n",
    "    cropped_dict = {}\n",
    "    for training_instance_id in range(0, len(patient_dictionary)):\n",
    "        cropped_dict[training_instance_id] = patient_dictionary[training_instance_id]\n",
    "        cropped_dict[training_instance_id].measurement_times = times[training_instance_id]\n",
    "        cropped_dict[training_instance_id].Mprotein_values = y[training_instance_id]\n",
    "\n",
    "    # Crop \"history\": Treatments in interval of interest, to length of M protein history\n",
    "    patient_id_and_treatment_index_list = []\n",
    "    for ii, patient in cropped_dict.items():\n",
    "        FOUND_LAST_RELEVANT_TREATMENT = False\n",
    "        for index, treat_i in enumerate(patient.treatment_history):\n",
    "            if not FOUND_LAST_RELEVANT_TREATMENT: # Only if we haven't found the end yet\n",
    "                if treat_i.end > patient.measurement_times[-1]:\n",
    "                    patient_id_and_treatment_index_list.append((ii, index))\n",
    "                    FOUND_LAST_RELEVANT_TREATMENT = True\n",
    "                    CROP_INDEX = index\n",
    "                    print(\"Yahoo\")\n",
    "    for elem in patient_id_and_treatment_index_list: \n",
    "        ii, index = elem[0], elem[1]\n",
    "        patient = cropped_dict[ii]\n",
    "        print(ii, index)\n",
    "        last_treatment_with_measurement = cropped_dict[ii].treatment_history[index]\n",
    "        cropped_dict[ii].treatment_history[index] = Treatment(last_treatment_with_measurement.start, patient.measurement_times[-1], last_treatment_with_measurement.id)\n",
    "        cropped_dict[ii].treatment_history = cropped_dict[ii].treatment_history[0:index+1]\n",
    "    return cropped_dict\n",
    "\n",
    "# X and patient_dictionary are passed on to the sampling\n",
    "X = feature_extraction(training_instance_dict, DATA_CHOICE=DATA_CHOICE)\n",
    "patient_dictionary = standardize_Y_arrays(patient_dictionary)\n",
    "# Check that dimensions are correct\n",
    "assert X.shape[0] == len(patient_dictionary)\n",
    "N_cases, P = X.shape\n",
    "print(\"N_cases:\", N_cases)\n",
    "print(patient_dictionary[0].treatment_history[-1].end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f596008",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(patient_dictionary[0].treatment_history[-1].end)\n",
    "print(patient_dictionary[0].measurement_times[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf14518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from full model\n",
    "psi_prior=\"normal\"\n",
    "N_samples = 30\n",
    "N_tuning = 30\n",
    "target_accept = 0.99\n",
    "max_treedepth = 10\n",
    "FUNNEL_REPARAMETRIZATION = True\n",
    "name = \"COMMPASS_linear_treat_id_\"+str(treat_id)+\"_M_\"+str(M_number_of_measurements)+\"_P_\"+str(P)+\"_N_cases_\"+str(N_cases)+\"_psi_prior_\"+psi_prior+\"_N_samples_\"+str(N_samples)+\"_N_tuning_\"+str(N_tuning)+\"_target_accept_\"+str(target_accept)+\"_max_treedepth_\"+str(max_treedepth)+\"_FUNNEL_REPARAMETRIZATION_\"+str(FUNNEL_REPARAMETRIZATION)\n",
    "print(\"Running\"+name)\n",
    "idata = sample_from_full_model(X, patient_dictionary, name, N_samples=N_samples, N_tuning=N_tuning, target_accept=target_accept, max_treedepth=max_treedepth, psi_prior=psi_prior, FUNNEL_REPARAMETRIZATION=FUNNEL_REPARAMETRIZATION)\n",
    "# This is an xArray: https://docs.xarray.dev/en/v2022.11.0/user-guide/data-structures.html\n",
    "print(\"Done sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db7eb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convergence checks\n",
    "def quasi_geweke_test(idata, first=0.1, last=0.5, intervals=20):\n",
    "    print(\"Running Geweke test...\")\n",
    "    convergence_flag = True\n",
    "    for var_name in ['alpha', 'beta_rho_s', 'beta_rho_r', 'beta_pi_r', 'omega', 'theta_rho_s', 'theta_rho_r', 'theta_pi_r', 'rho_s', 'rho_r', 'pi_r']:\n",
    "        sample_shape = idata.posterior[var_name].shape\n",
    "        n_chains = sample_shape[0]\n",
    "        n_samples = sample_shape[1]\n",
    "        var_dims = sample_shape[2]\n",
    "        for chain in range(n_chains):\n",
    "            for dim in range(var_dims):\n",
    "                all_samples = np.ravel(idata.posterior[var_name][chain,:,dim])\n",
    "                first_part = all_samples[0:int(n_samples*first)]\n",
    "                last_part = all_samples[n_samples-int(n_samples*last):n_samples]\n",
    "                z_score = (np.mean(first_part)-np.mean(last_part)) / np.sqrt(np.var(first_part)+np.var(last_part))\n",
    "                if abs(z_score) >= 1.960:\n",
    "                    convergence_flag = False\n",
    "                    print(\"Seems like chain\",chain,\"has not converged in\",var_name,\"dimension\",dim,\": z_score is\",z_score)\n",
    "    for var_name in ['sigma_obs']:\n",
    "        all_samples = np.ravel(idata.posterior[var_name])\n",
    "        n_samples = len(all_samples)\n",
    "        first_part = all_samples[0:int(n_samples*first)]\n",
    "        last_part = all_samples[n_samples-int(n_samples*last):n_samples]\n",
    "        z_score = (np.mean(first_part)-np.mean(last_part)) / np.sqrt(np.var(first_part)+np.var(last_part))\n",
    "        if abs(z_score) >= 1.960:\n",
    "            convergence_flag = False\n",
    "            print(\"Seems like chain\",chain,\"has not converged in\",var_name,\"dimension\",dim,\": z_score is\",z_score)\n",
    "    if convergence_flag:\n",
    "        print(\"All chains seem to have converged.\")\n",
    "    return 0\n",
    "\n",
    "quasi_geweke_test(idata, first=0.1, last=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3403a1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autocorrelation plots: \n",
    "az.plot_autocorr(idata, var_names=[\"sigma_obs\"]);\n",
    "az.plot_autocorr(idata, var_names=[\"alpha\"]);\n",
    "az.plot_autocorr(idata, var_names=[\"beta_rho_s\"]);\n",
    "az.plot_autocorr(idata, var_names=[\"beta_rho_r\"]);\n",
    "az.plot_autocorr(idata, var_names=[\"beta_pi_r\"]);\n",
    "az.plot_autocorr(idata, var_names=[\"omega\"]);\n",
    "az.plot_autocorr(idata, var_names=[\"sigma_obs\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29038eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior means \n",
    "print(\"List of covariates:\", idata.posterior.coords['predictors'])\n",
    "print('Posterior average of alpha:\\n', np.mean(idata.posterior['alpha'], axis=(0,1)))\n",
    "print('\\nPosterior average of beta_rho_s:\\n', np.mean(idata.posterior['beta_rho_s'], axis=(0,1)))\n",
    "print('\\nPosterior average of beta_rho_r:\\n', np.mean(idata.posterior['beta_rho_r'], axis=(0,1)))\n",
    "print('\\nPosterior average of beta_pi_r:\\n', np.mean(idata.posterior['beta_pi_r'], axis=(0,1)))\n",
    "print('\\nPosterior average of omega:\\n', np.mean(idata.posterior['omega'], axis=(0,1)))\n",
    "print('\\nPosterior average of sigma_obs:\\n', np.mean(idata.posterior['sigma_obs'], axis=(0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b894a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(idata, var_names=('alpha', 'beta_rho_s', 'beta_rho_r', 'beta_pi_r', 'omega', 'sigma_obs'), combined=True)\n",
    "plt.savefig(\"./plots/posterior_plots/\"+name+\"-plot_posterior_group_parameters.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094f1166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined means combine the chains into one posterior. Compact means split into different subplots\n",
    "az.plot_trace(idata, var_names=('beta_rho_s'), lines=[('beta_rho_s', {}, [0])], combined=False, compact=False)\n",
    "plt.savefig(\"./plots/posterior_plots/\"+name+\"-plot_posterior_uncompact_beta_rho_s.png\")\n",
    "# There seems to be an effect where Age contributes towards higher growth rate for sensitive cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc85ab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined means combine the chains into one posterior. Compact means split into different subplots\n",
    "az.plot_trace(idata, var_names=('beta_rho_r'), lines=[('beta_rho_r', {}, [0])], combined=False, compact=False)\n",
    "plt.savefig(\"./plots/posterior_plots/\"+name+\"-plot_posterior_uncompact_beta_rho_r.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9745c7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined means combine the chains into one posterior. Compact means split into different subplots\n",
    "az.plot_trace(idata, var_names=('beta_pi_r'), lines=[('beta_pi_r', {}, [0])], combined=False, compact=False)\n",
    "plt.savefig(\"./plots/posterior_plots/\"+name+\"-plot_posterior_uncompact_beta_pi_r.png\")\n",
    "# There is also an effect where there are less resistant cells for the older patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65e565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if psi_prior==\"lognormal\":\n",
    "    az.plot_trace(idata, var_names=('xi'), combined=True)\n",
    "    plt.savefig(\"./plots/posterior_plots/\"+name+\"-plot_posterior_group_parameters_xi.png\")\n",
    "    plt.close()\n",
    "az.plot_trace(idata, var_names=('theta_rho_s', 'theta_rho_r', 'theta_pi_r', 'rho_s', 'rho_r', 'pi_r'), combined=True)\n",
    "plt.savefig(\"./plots/posterior_plots/\"+name+\"-plot_posterior_individual_parameters.png\")\n",
    "plt.close()\n",
    "# Test of exploration \n",
    "az.plot_energy(idata)\n",
    "plt.savefig(\"./plots/posterior_plots/\"+name+\"-plot_energy.png\")\n",
    "plt.close()\n",
    "# Plot of coefficients\n",
    "az.plot_forest(idata, var_names=[\"alpha\"], combined=True, hdi_prob=0.95, r_hat=True)\n",
    "plt.savefig(\"./plots/posterior_plots/\"+name+\"-plot_forest_alpha.png\")\n",
    "az.plot_forest(idata, var_names=[\"beta_rho_s\"], combined=True, hdi_prob=0.95, r_hat=True, rope=(0,0))\n",
    "plt.savefig(\"./plots/posterior_plots/\"+name+\"-plot_forest_beta_rho_s.png\")\n",
    "plt.close()\n",
    "az.plot_forest(idata, var_names=[\"beta_rho_r\"], combined=True, hdi_prob=0.95, r_hat=True, rope=(0,0))\n",
    "plt.savefig(\"./plots/posterior_plots/\"+name+\"-plot_forest_beta_rho_r.png\")\n",
    "plt.close()\n",
    "az.plot_forest(idata, var_names=[\"beta_pi_r\"], combined=True, hdi_prob=0.95, r_hat=True, rope=(0,0))\n",
    "plt.savefig(\"./plots/posterior_plots/\"+name+\"-plot_forest_beta_pi_r.png\")\n",
    "plt.close()\n",
    "az.plot_forest(idata, var_names=[\"theta_rho_s\"], combined=True, hdi_prob=0.95, r_hat=True)\n",
    "plt.savefig(\"./plots/posterior_plots/\"+name+\"-plot_forest_theta_rho_s.png\")\n",
    "plt.close()\n",
    "az.plot_forest(idata, var_names=[\"theta_rho_r\"], combined=True, hdi_prob=0.95, r_hat=True)\n",
    "plt.savefig(\"./plots/posterior_plots/\"+name+\"-plot_forest_theta_rho_r.png\")\n",
    "plt.close()\n",
    "az.plot_forest(idata, var_names=[\"theta_pi_r\"], combined=True, hdi_prob=0.95, r_hat=True)\n",
    "plt.savefig(\"./plots/posterior_plots/\"+name+\"-plot_forest_theta_pi_r.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cca9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior distribution of y values\n",
    "sample_shape = idata.posterior['psi'].shape # [chain, n_samples, dim]\n",
    "n_chains = sample_shape[0]\n",
    "n_samples = sample_shape[1]\n",
    "var_dimensions = sample_shape[2]\n",
    "# Gather all the parameter estimates and get y values for each parameter set\n",
    "posterior_parameters = np.empty(shape=sample_shape, dtype=object)\n",
    "y_resolution = 80\n",
    "predicted_y_values = np.empty((sample_shape+(y_resolution,)))\n",
    "predicted_y_resistant_values = np.empty_like(predicted_y_values)\n",
    "for ii in range(var_dimensions): # per patient\n",
    "    patient = patient_dictionary[ii]\n",
    "    measurement_times = patient.get_measurement_times()\n",
    "    treatment_history = patient.get_treatment_history()\n",
    "    first_time = min(measurement_times[0], treatment_history[0].start)\n",
    "    plotting_times = np.linspace(first_time, int(measurement_times[-1]), y_resolution) #int((measurement_times[-1]+1)*10))\n",
    "    for ch in range(n_chains):\n",
    "        for sa in range(n_samples):\n",
    "            this_sigma_obs = np.ravel(idata.posterior['sigma_obs'][ch,sa])\n",
    "            this_psi       = np.ravel(idata.posterior['psi'][ch,sa,ii])\n",
    "            this_pi_r      = np.ravel(idata.posterior['pi_r'][ch,sa,ii])\n",
    "            this_rho_s     = np.ravel(idata.posterior['rho_s'][ch,sa,ii])\n",
    "            this_rho_r     = np.ravel(idata.posterior['rho_r'][ch,sa,ii])\n",
    "            posterior_parameters[ch,sa,ii] = Parameters(Y_0=this_psi, pi_r=this_pi_r, g_r=this_rho_r, g_s=this_rho_s, k_1=0, sigma=this_sigma_obs)\n",
    "            these_parameters = posterior_parameters[ch,sa,ii]\n",
    "            resistant_parameters = Parameters((these_parameters.Y_0*these_parameters.pi_r), 1, these_parameters.g_r, these_parameters.g_s, these_parameters.k_1, these_parameters.sigma)\n",
    "            # Predicted total M protein\n",
    "            predicted_y_values[ch,sa,ii] = measure_Mprotein_noiseless(these_parameters, plotting_times, treatment_history)\n",
    "            # Predicted resistant part\n",
    "            predicted_y_resistant_values[ch,sa,ii] = measure_Mprotein_noiseless(resistant_parameters, plotting_times, treatment_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8369408",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted_y_values[0,0,0].shape)\n",
    "print(predicted_y_resistant_values[0,0,0].shape)\n",
    "\n",
    "# Group measurements by patient and time\n",
    "flat_pred_y_values = np.reshape(predicted_y_values, (n_chains*n_samples,var_dimensions,1000))\n",
    "# sort the arrays of y\n",
    "sorted_pred_y_values = np.sort(flat_pred_y_values, axis=0)\n",
    "print(sorted_pred_y_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3fff07",
   "metadata": {},
   "outputs": [],
   "source": [
    "for training_instance_id, patient in patient_dictionary.items():\n",
    "    savename = \"./plots/Bayesian_estimates_COMMPASS_linearmodel/CI_training_id_\"+str(training_instance_id)+\"_treat_id_\"+str(treat_id)+\"_M_\"+str(M_number_of_measurements)+\"_P_\"+str(P)+\"_N_cases_\"+str(N_cases)+\"_psi_prior_\"+psi_prior+\"_N_samples_\"+str(N_samples)+\".png\"\n",
    "    plot_posterior_confidence_intervals(training_instance_id, patient, sorted_pred_y_values, parameter_estimates=[], PLOT_POINT_ESTIMATES=False, PLOT_TREATMENTS=False, plot_title=\"Posterior CI for patient \"+str(training_instance_id), savename=savename, y_resolution=y_resolution, n_chains=n_chains, n_samples=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea500dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior median M protein \n",
    "median_sigma_obs   = np.median(idata.posterior['sigma_obs'])\n",
    "print(\"Median sigma_obs:\", median_sigma_obs)\n",
    "median_psi_all_patients   = np.median(idata.posterior['psi'],   axis=(0,1))\n",
    "median_pi_r_all_patients  = np.median(idata.posterior['pi_r'],  axis=(0,1))\n",
    "median_rho_s_all_patients = np.median(idata.posterior['rho_s'], axis=(0,1))\n",
    "median_rho_r_all_patients = np.median(idata.posterior['rho_r'], axis=(0,1))\n",
    "\n",
    "# Dictionary of parameter estimates indexed by training_instance_id\n",
    "estimated_parameters_dict = {}\n",
    "for ii in range(N_cases): #ii = training_instance_id\n",
    "    estimated_parameters_dict[ii] = Parameters(Y_0=median_psi_all_patients[ii], pi_r=median_pi_r_all_patients[ii], g_r=median_rho_r_all_patients[ii], g_s=median_rho_s_all_patients[ii], k_1=0, sigma=median_sigma_obs)\n",
    "print(\"First patient's median parameters:\", estimated_parameters_dict[0].to_array_with_sigma())\n",
    "\n",
    "# Plot patient estimates\n",
    "for training_instance_id, patient in patient_dictionary.items():\n",
    "    estimated_parameters = estimated_parameters_dict[training_instance_id]\n",
    "    #patient.print()\n",
    "    savename = \"./plots/Bayesian_estimates/training_id_\"+str(training_instance_id)+\"_data_\"+DATA_CHOICE+\"_treat_id\"+str(treat_id)+\"_M_\"+str(M_number_of_measurements)+\"_P_\"+str(P)+\"_N_cases_\"+str(N_cases)+\"_psi_prior_\"+psi_prior+\"_N_samples_\"+str(N_samples)+\"_median_parameters__Y_0=\"+str(estimated_parameters.Y_0)+\", pi_r=\"+str(estimated_parameters.pi_r)+\", g_r=\"+str(estimated_parameters.g_r)+\", g_s=\"+str(estimated_parameters.g_s)+\", k_1=\"+str(estimated_parameters.k_1)+\", sigma=\"+str(estimated_parameters.sigma)+\".png\"\n",
    "    plot_treatment_region_with_estimate(estimated_parameters, patient, estimated_parameters=[], PLOT_ESTIMATES=False, plot_title=\"Posterior median for \"+str(training_instance_id), savename=savename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('second_pymc_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "df119888e8cfc4e804f2dbf8af55fd89351f3e519419fe2f4c1dbc596db198bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
